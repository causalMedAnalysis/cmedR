% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dmlmed.R
\name{dmlmed}
\alias{dmlmed}
\title{Debiased Machine Learning Estimation for Natural Effects}
\usage{
dmlmed(
  D,
  Y,
  M,
  C,
  D_C_model,
  D_MC_model = NULL,
  Y_DC_model = NULL,
  Y_DMC_model,
  M_DC_model = NULL,
  data,
  d,
  dstar,
  K = 5,
  V = 5L,
  seed,
  SL.library = c("SL.mean", "SL.glmnet"),
  stratifyCV = TRUE,
  minimal = TRUE,
  censor = TRUE,
  censor_low = 0.01,
  censor_high = 0.99
)
}
\arguments{
\item{D}{A character scalar identifying the name of the exposure variable in
\code{data}. \code{D} is a character string, but the exposure variable it identifies
must be numeric and binary, with two distinct values.}

\item{Y}{A character scalar identifying the name of the outcome variable in
\code{data}. \code{Y} is a character string, but the outcome variable it identifies
must be numeric.}

\item{M}{A character vector (of one or more elements) identifying the names
of the mediator variables in \code{data}. If you are estimating univariate
natural effects (with a single mediator), \code{M} should be a character scalar
(i.e., a vector with only one element)—e.g., \code{M = "ever_unemp_age3539"}. If you
are estimating multivariate natural effects (with multiple mediators), \code{M}
should be a list identifying all mediators—e.g.,
\code{M = list("ever_unemp_age3539", "log_faminc_adj_age3539")}.}

\item{C}{A character vector (of one or more elements) identifying the names
of the covariate variables in \code{data} that you wish to include in both the
mediator and outcome models. If there are no such covariates you wish to
include, leave \code{C} as its default null argument.}

\item{D_C_model}{A character scalar specifying the formula to be fitted for a
model of the exposure given baseline covariates (denoted in the book as
π(D|C)). This specification is required for Type 1 and Type 2 estimators. E.g.,
\code{D_C_model = "att22 ~ female + black + hispan + paredu + parprof + parinc_prank + famsize + afqt3"}.}

\item{D_MC_model}{A character scalar specifying the formula to be fitted for a
model of the exposure given baseline covariates and the mediator(s)
(denoted in the book as π(D|C,M)). This specification is required only for
Type 2 estimation. When this input is not NULL, the model will compute the Type 2
estimator by default. E.g.,
\code{D_MC_model = "att22 ~ female + black + hispan + paredu + parprof + parinc_prank + famsize + afqt3 + ever_unemp_age3539"}.}

\item{Y_DC_model}{A character scalar specifying the formula to be fitted for a
model of the conditional mean of μ(Y|C,M,D) given baseline covariates
and the treatment variable (denoted in the book as ν_D(C)). This specification
allows the user to specify interactions between D and C. In implementation,
the outcome variable is substituted with the estimated conditional mean from
the \code{Y_DMC_model}. This specification is required only for Type 2 estimation.
When this input is not NULL, the model will compute the Type 2 estimator by
default. E.g.,
\code{Y_DC_model = "std_cesd_age40 ~ female + black + hispan + paredu + parprof + parinc_prank + famsize + afqt3 + att22"}.}

\item{Y_DMC_model}{A character scalar specifying the formula to be fitted for a
model of the outcome given baseline covariates, mediator(s), and the
treatment variable (denoted in the book as μ(Y|C,M,D)). This specification is
required for both Type 1 and Type 2 estimators. E.g.,
\code{Y_DMC_model = "std_cesd_age40 ~ female + black + hispan + paredu + parprof + parinc_prank + famsize + afqt3 + att22 + ever_unemp_age3539"}.}

\item{M_DC_model}{A character scalar specifying the formula to be fitted for a
model of P(M|C,D), the conditional probability of the mediator given baseline covariates
and the treatment variable. This specification allows the user to specify
interactions between D and C, and is required only for Type 1 estimation.
When this input is not NULL, the model will compute the Type 1 estimator by default. E.g.,
\code{M_DC_model = "ever_unemp_age3539 ~ female + black + hispan + paredu + parprof + parinc_prank + famsize + afqt3 + att22"}.}

\item{data}{A data frame.}

\item{d}{The numeric value of the treatment variable that the user defines as
the treatment status. If not equal to 1, the function will recode it as 1.}

\item{dstar}{The numeric value of the treatment variable that the user defines
as the control status. If not equal to 0, the function will recode it as 0.}

\item{K}{Integer. The number of folds (partitions) used for repeated cross-fitting.
The data is randomly divided into \code{K} approximately equal-sized subsets.
Models are trained on \code{K - 1} folds and evaluated on the held-out fold.
The procedure is repeated across all partitions. Typical values range from 4 to 10.
The default number is \code{5}.}

\item{V}{Integer. The number of folds used in the Super Learner's internal cross-validation.
procedure for training and evaluating candidate algorithms. Must be an explicit
integer (e.g., \code{5L}) to ensure proper handling by certain functions. Smaller sample
sizes may benefit from a higher \code{V} to better balance bias and variance
in model evaluation. The default number is \code{5L}.}

\item{seed}{Seed value for reproducibility. Controls the randomization in cross-validation
and other stochastic components of the procedure.}

\item{SL.library}{Character vector. Specifies the set of candidate algorithms to be
used in the Super Learner ensemble. Each element should be the name of a valid learner
(e.g., \code{"SL.mean"}, \code{"SL.glmnet"}, \code{"SL.ranger"}). Learners can
be chosen from base learners available in the \pkg{SuperLearner} package or user-defined wrappers.
The default setting is \code{c("SL.mean", "SL.glmnet")}.}

\item{stratifyCV}{Logical. If \code{TRUE}, stratified sampling is used when creating cross-validation
folds within each Super Learner, preserving the distribution of the outcome variable
across folds. This is especially useful for binary or imbalanced outcomes. The default setting
is \code{TRUE}.}

\item{minimal}{A logical scalar indicating whether the function should
return only a minimal set of output.}

\item{censor}{A logical scalar indicating whether the IPW weights used in the DML estimators
should be censored. By default, this value is \code{TRUE}.}

\item{censor_low, censor_high}{A pair of arguments, each a numeric scalar
denoting a probability in [0,1]. If \code{censor} is TRUE, then IPW weights below
the \code{censor_low} quantile will be bottom-coded, and weights above the
\code{censor_high} quantile will be top-coded. E.g., if the default values
\code{censor_low = 0.01} and \code{censor_high = 0.99} are used, then IPW weights will
be censored at their 1st and 99th percentiles. By default, weights are censored
to the [1st, 99th] percentile range.}
}
\value{
Based on the user's specification, \code{dmlmed()} returns a list with the
following elements:

\item{est1, est2}{A tibble containing the point estimates, standard errors, and
95\% confidence intervals for \eqn{ATE(1,0)}, \eqn{NDE(1,0)}, and \eqn{NIE(1,0)}}.

If \code{minimal} is set to \code{FALSE}, the function will return the following additional items,
along with a summary of missingness for the input data:

\item{df1, df2}{Data frames containing the calculated \eqn{S_{d(\ast), d(\ast)}} objects,
using method 1 or method 2.}
}
\description{
\code{dmlmed()} uses debiased machine learning to estimate the total effect (ATE)
natural direct effect (NDE), and natural indirect effect (NIE). The function
supports estimation of both single mediator and multiple mediator effects.
}
\details{
The estimator implemented in \code{dmlmed()} follows the debiased machine learning (DML) framework
of Chernozhukov et al. (2018), combining machine learning with repeated cross-fitting
to enable valid inference for causal effects. The method addresses bias that can
arise when the same data are used to both estimate high-dimensional nuisance functions and
evaluate treatment effects.

By separating the data used to estimate nuisance functions from the data used to estimate the
target effect, and by repeating this process across multiple folds, DML reduces overfitting bias
and allows for robust inference. The resulting estimator is \eqn{\sqrt{n}}-consistent and normal,
even if the nuisance models are not themselves \eqn{\sqrt{n}}-consistent. This is made possible
by the multiplicative form of the bias: convergence is guaranteed if the product of the nuisance
model convergence rates exceeds \eqn{n^{-1/2}}, which can be achieved using many modern machine
learning methods such as LASSO, random forests, or neural networks.

The function accommodates two types of identification strategies based on user-specified
nuisance functions:
\itemize{
\item \strong{Type 1 Specification}: Requires an exposure model (π(D|C)), a mediator model (P(M|D,C)),
and an outcome model (μ(Y|C,M,D)).
\item \strong{Type 2 Specification}: Requires two exposure models (π(D|C) and π(D|C,M)), and two outcome
models (μ(Y|C,M,D) and its projected version ν_D(C)). This setup is particularly well-suited
for analyses of multivariate mediators.
}
}
\examples{
#------------------------------------------#
# Initial Specification and Clean the Data:
#------------------------------------------#
data(nlsy)
# outcome
Y <- "std_cesd_age40"

# exposure
D <- "att22"

# mediators
M <- list(
"ever_unemp_age3539",
"log_faminc_adj_age3539"
)

# baseline confounders:
C <- c(
"female",
"black",
"hispan",
"paredu",
"parprof",
"parinc_prank",
"famsize",
"afqt3"
)

# key variables
key_vars <- c(
 "cesd_age40",
  D,
  unlist(M),
  C
)

# Clean the Data:
df <- nlsy[complete.cases(nlsy[,key_vars]),] |>
dplyr::mutate(std_cesd_age40 = (cesd_age40 - mean(cesd_age40)) / sd(cesd_age40))

#-----------------------------------------#
#  Specify the models:
#----------------------------------------#
# D Models:
D_C_model <- as.formula(paste(D, " ~ ", paste(C, collapse= "+")))
D_MC_model <- as.formula(paste(D, " ~ ", paste(c(C, M[1]), collapse= "+")))
# M model:
M_DC_model <- as.formula(paste(M[1], " ~ ", paste(c(C, D), collapse= "+")))
# Y Models:
Y_DC_model <- as.formula(paste(Y, " ~ ", paste(c(C, D), collapse= "+")))
Y_DMC_model <- as.formula(paste(Y, " ~ ", paste(c(C, D, M[1]), collapse= "+")))

# ---------------------------------------------- #
# Example 1: Single mediator — Type 2 estimator  #
# Super Learner: Marginal mean and Lasso         #
# ---------------------------------------------- #
dmlmed(
  D,
  Y,
  M[[1]],
  C,
  D_C_model,              # π(D|C)
  D_MC_model,             # π(D|C,M)
  Y_DC_model,             # ν_D(C)
  Y_DMC_model,            # μ(Y|C,M,D)
  M_DC_model = NULL,      # NULL → Type 2
  data = df,
  d = 1, dstar = 0,
  K = 5, V = 5L, seed = 1234,
  SL.library = c("SL.mean", "SL.glmnet"),
  stratifyCV = TRUE,
  minimal = TRUE,
  censor = TRUE, censor_low = 0.01, censor_high = 0.99
)

# ------------------------------------------------------------ #
# Example 2: Single mediator — Type 2 estimator                #
# Super Learner: Marginal mean, Lasso and Random forest        #
# ------------------------------------------------------------ #
\dontrun{
dmlmed(
  D,
  Y,
  M[[1]],
  C,
  D_C_model,              # π(D|C)
  D_MC_model,             # π(D|C,M)
  Y_DC_model,             # ν_D(C)
  Y_DMC_model,            # μ(Y|C,M,D)
  M_DC_model = NULL,      # NULL → Type 2
  data = df,
  d = 1, dstar = 0,
  K = 5, V = 5L, seed = 1234,
  SL.library = c("SL.mean", "SL.glmnet", "SL.ranger"),
  stratifyCV = TRUE,
  minimal = TRUE,
  censor = TRUE, censor_low = 0.01, censor_high = 0.99
)
}

# ------------------------------------------------------- #
# Example 3: Single mediator — Type 1 estimator           #
# Super Learner: Marginal mean, Lasso and Random forest   #
# ------------------------------------------------------- #
# (Switch to Type 1 by supplying P(M|D,C) and dropping
#  π(D|C,M) and ν_D(C).)
\dontrun{
dmlmed(
  D,
  Y,
  M[[1]],
  C,
  D_C_model,               # π(D|C)
  D_MC_model = NULL,       # not used in Type 1
  Y_DC_model = NULL,       # not used in Type 1
  Y_DMC_model,             # μ(Y|C,M,D)
  M_DC_model,              # P(M|D,C) → Type 1
  data = df,
  d = 1, dstar = 0,
  K = 5, V = 5L, seed = 1234,
  SL.library = c("SL.mean", "SL.glmnet", "SL.ranger"),
  stratifyCV = TRUE,
  minimal = TRUE,
  censor = TRUE, censor_low = 0.01, censor_high = 0.99
)
}

# -------------------------------------------------------- #
# Example 4: Multiple mediators — Type 2 estimator         #
# Super Learner: Marginal mean, Lasso and Random forest    #
# -------------------------------------------------------- #
# Update π(D|C,M) and μ(Y|C,M,D) to include all mediators
D_MC_model_multi  <- as.formula(paste(D, " ~ ", paste(c(C, unlist(M)), collapse = "+")))
Y_DMC_model_multi <- as.formula(paste(Y, " ~ ", paste(c(C, D, unlist(M)), collapse = "+")))
\dontrun{
dmlmed(
  D,
  Y,
  M,                        #full mediator list
  C,
  D_C_model,                # π(D|C)
  D_MC_model_multi,         # π(D|C,M1,M2,…)
  Y_DC_model,               # ν_D(C)
  Y_DMC_model_multi,        # μ(Y|C,M1,M2,…,D)
  M_DC_model = NULL,        # NULL → Type 2
  data = df,
  d = 1, dstar = 0,
  K = 5, V = 5L, seed = 1234,
  SL.library = c("SL.mean", "SL.glmnet", "SL.ranger"),
  stratifyCV = TRUE,
  minimal = TRUE,
  censor = TRUE, censor_low = 0.01, censor_high = 0.99
)
}

}
